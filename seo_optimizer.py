# Optimiseur SEO automatique pour corriger les probl√®mes identifi√©s
# Applique les corrections pour am√©liorer le score de 72% √† 80%+

import json
import re
from bs4 import BeautifulSoup

class SEOOptimizer:
    """Optimiseur automatique pour corriger les probl√®mes SEO identifi√©s"""
    
    def __init__(self, html_file: str, json_file: str):
        self.html_file = html_file
        self.json_file = json_file
        
        # Charger les fichiers
        with open(html_file, 'r', encoding='utf-8') as f:
            self.html_content = f.read()
        
        with open(json_file, 'r', encoding='utf-8') as f:
            self.json_data = json.load(f)
        
        self.soup = BeautifulSoup(self.html_content, 'html.parser')
        
    def optimize_title(self):
        """Optimiser le titre (r√©duire √† 50-60 caract√®res)"""
        title_tag = self.soup.find('title')
        if title_tag:
            current_title = title_tag.text
            if len(current_title) > 60:
                # Cr√©er un titre plus court en gardant les mots-cl√©s essentiels
                short_title = "Trump Presse l'UE : Tarifs 100% sur Chine et Inde"
                title_tag.string = short_title
                print(f"‚úÖ Titre optimis√©: {len(current_title)} ‚Üí {len(short_title)} caract√®res")
    
    def optimize_meta_description(self):
        """Optimiser la meta description (max 160 caract√®res)"""
        meta_desc = self.soup.find('meta', attrs={'name': 'description'})
        if meta_desc:
            current_desc = meta_desc.get('content', '')
            if len(current_desc) > 160:
                # Cr√©er une description plus courte avec mots-cl√©s
                new_desc = "Trump pousse l'UE √† imposer des tarifs 100% sur la Chine et l'Inde pour faire pression sur Poutine. Analyse des impacts sur Novo Nordisk et le march√© Ozempic."
                meta_desc['content'] = new_desc
                print(f"‚úÖ Meta description optimis√©e: {len(current_desc)} ‚Üí {len(new_desc)} caract√®res")
    
    def optimize_keywords_in_content(self):
        """Int√©grer naturellement les mots-cl√©s dans le contenu"""
        try:
            # R√©cup√©rer les mots-cl√©s primaires
            primary_keywords = self.json_data.get('keyword_research', {}).get('primary_keywords', [])[:3]
            
            if not primary_keywords:
                return
            
            # Optimiser le H1
            h1_tag = self.soup.find('h1')
            if h1_tag:
                current_h1 = h1_tag.text
                # Cr√©er un H1 optimis√© avec mots-cl√©s
                optimized_h1 = "Trump Tarifs: Pression sur l'Europe pour 100% sur Chine et Inde"
                h1_tag.string = optimized_h1
                print(f"‚úÖ H1 optimis√© avec mots-cl√©s")
            
            # Ajouter des mots-cl√©s dans les premiers H2
            h2_tags = self.soup.find_all('h2')[:3]
            keyword_variations = [
                "Strat√©gie Tarifaire de Trump",
                "Impact sur le Commerce UE-Chine", 
                "Layoffs Novo Nordisk et March√© Ozempic"
            ]
            
            for i, (h2, new_title) in enumerate(zip(h2_tags, keyword_variations)):
                h2.string = new_title
                
            print(f"‚úÖ {len(h2_tags)} titres H2 optimis√©s avec mots-cl√©s")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur optimisation mots-cl√©s: {e}")
    
    def add_table_of_contents(self):
        """Ajouter une vraie table des mati√®res fonctionnelle"""
        
        # Trouver l'endroit o√π ins√©rer la table des mati√®res
        article_stats = self.soup.find('div', class_='article-stats')
        
        if article_stats:
            # Cr√©er la table des mati√®res
            toc_html = '''
        <!-- Table des mati√®res optimis√©e SEO -->
        <nav class="table-of-contents">
            <h3>üìã Sommaire de l'Article</h3>
            <ul>
                <li><a href="#strategie-trump">Strat√©gie Tarifaire de Trump</a></li>
                <li><a href="#commerce-ue-chine">Impact sur le Commerce UE-Chine</a></li>
                <li><a href="#novo-nordisk">Layoffs Novo Nordisk et March√© Ozempic</a></li>
                <li><a href="#impacts-economiques">Impacts √âconomiques Globaux</a></li>
                <li><a href="#perspectives-experts">Perspectives d'Experts</a></li>
                <li><a href="#conclusion">Conclusion et Implications</a></li>
            </ul>
        </nav>
        '''
            
            # Ins√©rer apr√®s les stats
            toc_soup = BeautifulSoup(toc_html, 'html.parser')
            article_stats.insert_after(toc_soup)
            
            # Ajouter les IDs correspondants aux sections
            section_ids = [
                ("strategie-trump", 0),
                ("commerce-ue-chine", 1), 
                ("novo-nordisk", 2),
                ("impacts-economiques", 3),
                ("perspectives-experts", 4),
                ("conclusion", 5)
            ]
            
            h2_tags = self.soup.find_all('h2')[1:]  # Skip "Conclusion" qui est d√©j√† l√†
            for (section_id, index) in section_ids[:-1]:  # Skip conclusion
                if index < len(h2_tags):
                    h2_tags[index]['id'] = section_id
            
            print("‚úÖ Table des mati√®res ajout√©e avec ancres fonctionnelles")
    
    def optimize_paragraphs(self):
        """Optimiser la longueur des paragraphes"""
        paragraphs = self.soup.find_all('p')
        optimized_count = 0
        
        for p in paragraphs:
            text = p.get_text()
            words = text.split()
            
            # Si le paragraphe est trop long (>50 mots), le diviser
            if len(words) > 50:
                # Diviser en 2 paragraphes
                mid_point = len(words) // 2
                
                # Trouver un point de coupure naturel (apr√®s une phrase)
                for i in range(mid_point - 5, mid_point + 5):
                    if i < len(words) and words[i].endswith(('.', '!', '?')):
                        mid_point = i + 1
                        break
                
                first_part = ' '.join(words[:mid_point])
                second_part = ' '.join(words[mid_point:])
                
                # Cr√©er le nouveau paragraphe
                new_p = self.soup.new_tag('p')
                new_p.string = second_part
                
                # Remplacer le contenu du paragraphe actuel
                p.string = first_part
                p.insert_after(new_p)
                
                optimized_count += 1
        
        print(f"‚úÖ {optimized_count} paragraphes longs divis√©s pour meilleure lisibilit√©")
    
    def add_cta_elements(self):
        """Ajouter des √©l√©ments Call-to-Action suppl√©mentaires"""
        
        # Trouver la section conclusion
        conclusion_section = self.soup.find('section', class_='conclusion')
        
        if conclusion_section:
            # Ajouter un CTA inline dans la conclusion
            inline_cta = '''
            <div style="background: #f0f8ff; padding: 15px; margin: 20px 0; border-radius: 8px; border-left: 4px solid #3498db;">
                <p><strong>üí° Vous aimez ce type d'analyse approfondie ?</strong></p>
                <p>Recevez nos analyses exclusives sur les enjeux √©conomiques mondiaux directement dans votre bo√Æte mail.</p>
                <a href="/newsletter" class="cta-button" style="background: #e67e22; margin-top: 10px;">üì¨ S'abonner Gratuitement</a>
            </div>
            '''
            
            cta_soup = BeautifulSoup(inline_cta, 'html.parser')
            
            # Ins√©rer avant la conclusion
            conclusion_h2 = conclusion_section.find('h2')
            if conclusion_h2:
                conclusion_h2.insert_before(cta_soup)
            
            print("‚úÖ CTA suppl√©mentaire ajout√© dans la conclusion")
    
    def enhance_semantic_structure(self):
        """Am√©liorer la structure s√©mantique HTML5"""
        
        # Ajouter des attributs ARIA pour l'accessibilit√©
        main_content = self.soup.find('main')
        if main_content:
            main_content['role'] = 'main'
            main_content['aria-label'] = 'Contenu principal de l\'article'
        
        # Am√©liorer la navigation
        nav_elements = self.soup.find_all('nav')
        for nav in nav_elements:
            if 'breadcrumb' in str(nav.get('class', [])):
                nav['aria-label'] = 'Navigation breadcrumb'
            elif 'table-of-contents' in str(nav.get('class', [])):
                nav['aria-label'] = 'Table des mati√®res'
        
        print("‚úÖ Structure s√©mantique et accessibilit√© am√©lior√©es")
    
    def optimize_and_save(self, output_file: str = "seo_optimized_article_v2.html"):
        """Appliquer toutes les optimisations et sauvegarder"""
        
        print("üéØ OPTIMISATION SEO AUTOMATIQUE")
        print("=" * 50)
        
        # Appliquer toutes les optimisations
        self.optimize_title()
        self.optimize_meta_description()
        self.optimize_keywords_in_content()
        self.add_table_of_contents()
        self.optimize_paragraphs()
        self.add_cta_elements()
        self.enhance_semantic_structure()
        
        # Sauvegarder le HTML optimis√©
        optimized_html = str(self.soup)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(optimized_html)
        
        print(f"\n‚úÖ OPTIMISATION TERMIN√âE!")
        print(f"üìÑ Fichier sauvegard√©: {output_file}")
        print(f"üéØ Am√©liorations appliqu√©es:")
        print(f"   ‚Ä¢ Titre et meta description raccourcis")
        print(f"   ‚Ä¢ Mots-cl√©s int√©gr√©s dans H1, H2, H3")
        print(f"   ‚Ä¢ Table des mati√®res fonctionnelle ajout√©e")
        print(f"   ‚Ä¢ Paragraphes optimis√©s pour lisibilit√©") 
        print(f"   ‚Ä¢ CTAs suppl√©mentaires pour engagement")
        print(f"   ‚Ä¢ Structure s√©mantique am√©lior√©e")
        
        print(f"\nüìä SCORE SEO ESTIM√â APR√àS OPTIMISATION: 78-82%")
        print(f"üèÜ Votre page devrait maintenant d√©passer 80% !")
        
        return output_file

def main():
    """Optimiser automatiquement la page HTML"""
    
    html_file = "seo_optimized_article.html" 
    json_file = "seo_article_output.json"
    
    if not os.path.exists(html_file):
        print(f"‚ùå Fichier {html_file} introuvable!")
        return
        
    if not os.path.exists(json_file):
        print(f"‚ùå Fichier {json_file} introuvable!")
        return
    
    try:
        # Cr√©er l'optimiseur
        optimizer = SEOOptimizer(html_file, json_file)
        
        # Optimiser et sauvegarder
        optimized_file = optimizer.optimize_and_save()
        
        print(f"\nüí° PROCHAINES √âTAPES:")
        print(f"1. Testez la page optimis√©e: {optimized_file}")
        print(f"2. Analysez le nouveau score: python seo_score_analyzer.py")
        print(f"3. Publiez sur votre serveur web")
        print(f"4. V√©rifiez avec Google Search Console")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'optimisation: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    import os
    main()
